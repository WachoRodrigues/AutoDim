{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "#Function import\n",
    "from ipynb.fs.full.autoXRD import normdata\n",
    "from ipynb.fs.full.autoXRD import normdatasingle\n",
    "from ipynb.fs.full.autoXRD import augdata\n",
    "from ipynb.fs.full.autoXRD import exp_augdata\n",
    "from ipynb.fs.full.autoXRD import exp_data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2402, 1468)\n",
      "(2401, 1468)\n",
      "(2401, 734)\n"
     ]
    }
   ],
   "source": [
    "#Import simulated XRD\n",
    "theor = pd.read_csv('Datasets/theor.csv', index_col=0)\n",
    "print(theor.shape)\n",
    "theor = theor.iloc[1:,]\n",
    "theor_arr = theor.values\n",
    "print(theor_arr.shape)\n",
    "\n",
    "# Normalize data for training\n",
    "ntheor = normdata(theor_arr)\n",
    "print(ntheor.shape)\n",
    "\n",
    "#exp = pd.read_csv('Datasets/exp.csv', index_col=0)\n",
    "#exp_arr = exp.values\n",
    "#print(exp_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468\n",
      "(2401, 734)\n"
     ]
    }
   ],
   "source": [
    "#Import dimensionalities\n",
    "label_theo = pd.read_csv('Datasets/label_theo_dataaug.csv', header=None, index_col=0)\n",
    "label_theo = label_theo[1].tolist()\n",
    "\n",
    "# Load experimental class labels\n",
    "#label_exp= pd.read_csv('Datasets/label_theo.csv', index_col=0).values\n",
    "#label_exp = label_exp.reshape([len(label_exp),])\n",
    "\n",
    "space_group_enc = pd.read_csv('Datasets/encoding.csv', index_col=0)\n",
    "space_group_enc = list(space_group_enc['0'])\n",
    "\n",
    "print(len(label_theo))\n",
    "print(ntheor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2401, 2000)\n",
      "(1500, 2000)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "#augdata(data,num,par1,minn,maxn)\n",
    "# Specify how many data points we augmented\n",
    "th_num = 2000\n",
    "\n",
    "# Define 2theta range for data augmentation\n",
    "exp_min = 0\n",
    "exp_max = 1500\n",
    "theor_min = 0\n",
    "theor_max = theor_min+exp_max-exp_min\n",
    "\n",
    "# Perform data augmentation\n",
    "augd, pard, crop_augd = augdata(ntheor, th_num, label_theo, theor_min, theor_max) \n",
    "\n",
    "# Enconde theoretical labels\n",
    "label_t = np.zeros([len(pard),])\n",
    "for i in range(len(pard)):\n",
    "    label_t[i] = space_group_enc.index(pard[i])\n",
    "\n",
    "print(augd.shape)\n",
    "print(crop_augd.shape)\n",
    "print(label_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1500, 1)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "#prepare X et Y\n",
    "X_th = np.transpose(crop_augd)\n",
    "#X_th = X_th.reshape(734, 2401, 1)\n",
    "X_th = X_th.reshape(th_num, exp_max-exp_min, 1)\n",
    "Y_th = label_t\n",
    "\n",
    "X_th = X_th.astype(np.float32)\n",
    "Y_th = Y_th.astype(np.float32)\n",
    "\n",
    "print(X_th.shape)\n",
    "print(Y_th.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_th_train (1600, 1500, 1)\n",
      "X_th_valid (400, 1500, 1)\n",
      "Y_th_train (1600,)\n",
      "Y_th_valid (400,)\n",
      "<TensorSliceDataset shapes: ((1500, 1), ()), types: (tf.float32, tf.float32)>\n",
      "<TensorSliceDataset shapes: ((1500, 1), ()), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "# Introduction de set de test à partir de la base de données\n",
    "# Definition du set de test 20% d'images random\n",
    "# Avec cette ligne on definit set de images et targets pour l'entrainement et test\n",
    "X_th_train, X_th_valid, Y_th_train, Y_th_valid = train_test_split(X_th, Y_th, test_size=0.2, random_state=1)\n",
    "\n",
    "print(\"X_th_train\", X_th_train.shape)\n",
    "print(\"X_th_valid\", X_th_valid.shape)\n",
    "\n",
    "print(\"Y_th_train\", Y_th_train.shape)\n",
    "print(\"Y_th_valid\", Y_th_valid.shape)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_th, Y_th))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_th_valid, Y_th_valid))\n",
    "\n",
    "print(train_dataset)\n",
    "print(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1500, 1) (32,)\n"
     ]
    }
   ],
   "source": [
    "# Iter in the dataset with a number of epoch and batch size\n",
    "epoch = 1\n",
    "batch_size = 32\n",
    "for X_th_batch, Y_th_batch in train_dataset.repeat(epoch).batch(batch_size):\n",
    "    print(X_th_batch.shape, Y_th_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        # Convolutions\n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=64, kernel_size=20, strides=1, padding='same', activation='relu', name=\"conv1\")\n",
    "        self.pool1 = tf.compat.v1.layers.MaxPooling1D(pool_size=3, strides=3, padding='same', name=\"pool1\")\n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=64, kernel_size=15, strides=1, padding='same', activation='relu', name=\"conv2\")\n",
    "        self.pool2 = tf.compat.v1.layers.MaxPooling1D(pool_size=2, strides=3, padding='same', name=\"pool2\")\n",
    "        self.conv3 = tf.keras.layers.Conv1D(filters=64, kernel_size=10, strides=1, padding='same', activation='relu', name=\"conv3\")\n",
    "        self.pool3 = tf.compat.v1.layers.MaxPooling1D(pool_size=1, strides=2, padding='same', name=\"pool3\")\n",
    "        # Flatten the convolution\n",
    "        self.flatten = tf.keras.layers.Flatten(name=\"flatten\")       \n",
    "        # Dense layers\n",
    "        self.d1 = tf.keras.layers.Dense(256, activation='relu', name=\"d1\")\n",
    "        self.d2 = tf.keras.layers.Dense(128, activation='relu', name=\"d2\")\n",
    "        self.out = tf.keras.layers.Dense(4, activation='softmax', name=\"output\")\n",
    "\n",
    "    def call(self, X_th):\n",
    "        conv1 = self.conv1(X_th)\n",
    "        pool1 = self.pool1(conv1)\n",
    "        conv2 = self.conv2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "        conv3 = self.conv3(pool2)\n",
    "        pool3 = self.pool1(conv3)\n",
    "        #print(conv3)\n",
    "        flatten = self.flatten(pool3)\n",
    "        #print(flatten)\n",
    "        d1 = self.d1(flatten)\n",
    "        d2 = self.d2(d1)\n",
    "        #print(d1)\n",
    "        output = self.out(d2)\n",
    "        return output\n",
    "\n",
    "model = ConvModel()\n",
    "#model.predict(X_th[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss, optimizer, accuracy for th emodel to compile\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Loss\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "# Accuracy\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition de la fonction qui va entrainer le modele\n",
    "# On utilise un graphe @\n",
    "@tf.function\n",
    "def train_step(X_th, Y_th):\n",
    "    # Calcul du gradient\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make a prediction on all the batch\n",
    "        predictions = model(X_th)\n",
    "        # Get the error/loss on these predictions\n",
    "        loss = loss_object(Y_th, predictions)\n",
    "    # Compute the gradient which respect to the loss\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # Change the weights of the model\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    # The metrics are accumulate over time. You don't need to average it yourself.\n",
    "    train_loss(loss)\n",
    "    train_accuracy(Y_th, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode de validation en mode graphe\n",
    "@tf.function\n",
    "def valid_step(X_th, Y_th):\n",
    "    predictions = model(X_th)\n",
    "    t_loss = loss_object(Y_th, predictions)\n",
    "    # Set the metrics for the test\n",
    "    valid_loss(t_loss)\n",
    "    valid_accuracy(Y_th, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 1920/2000, Loss: 0.9702702760696411, Accuracy: 63.529167938232426\n",
      "Epoch 1, Valid Loss: 0.7309810519218445, Valid Accuracy: 78.75\n",
      " Batch 3584/2000, Loss: 0.6980214715003967, Accuracy: 76.38221740722656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-643c16b79b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mX_th_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_th_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#Iteration dans la dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_th_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_th_batch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#On lance un entrainement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\r Batch {}/{}, Loss: {}, Accuracy: {}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         print(template.format(\n",
      "\u001b[1;32mc:\\users\\thibault\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thibault\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thibault\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thibault\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thibault\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thibault\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\thibault\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Iteration du modele\n",
    "epoch = 20\n",
    "batch_size = 128\n",
    "b = 0 #Compter les batchs\n",
    "for epoch in range(epoch):\n",
    "    # Training set\n",
    "    for X_th_batch, Y_th_batch in train_dataset.batch(batch_size): #Iteration dans la dataset\n",
    "        train_step(X_th_batch, Y_th_batch) #On lance un entrainement\n",
    "        template = '\\r Batch {}/{}, Loss: {}, Accuracy: {}'\n",
    "        print(template.format(\n",
    "            b, len(Y_th), train_loss.result(), \n",
    "            train_accuracy.result()*100\n",
    "        ), end=\"\") #Informations de l'entrainement\n",
    "        b += batch_size\n",
    "    # Validation set\n",
    "    for X_th_batch, Y_th_batch in valid_dataset.batch(batch_size):\n",
    "        valid_step(X_th_batch, Y_th_batch) #Mesure precision sur chacun des batch\n",
    "\n",
    "    template = '\\nEpoch {}, Valid Loss: {}, Valid Accuracy: {}'\n",
    "    print(template.format(\n",
    "        epoch+1,\n",
    "        valid_loss.result(), \n",
    "        valid_accuracy.result()*100)\n",
    "    )\n",
    "    #A la fin de chaque epoch on vide\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_th[:,:,:])\n",
    "print(res.shape)\n",
    "for i in range(200, 250):\n",
    "    print(res[i], label_theo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.shape)\n",
    "for i in range(1, 10):\n",
    "    print(res[i], label_theo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO2debwcVZm/n7f7LgkhkCBh313BBZWIKDrihiyDMDOOP2RUREcGxRlmdEbQUcfRcUDRGQdBM4jIpuICAwHDLkvYQkL2kITcJJfkZr1ZbnJzt17q/P6oXqq7q7qru6uXqn6fzye53VWnTp1+q+p73nrPJsYYFEVRlPATa3UBFEVRlGBQQVcURYkIKuiKoigRQQVdURQlIqigK4qiRISuVp344IMPNscdd1yrTq8oihJKXnzxxR3GmBlu+1om6McddxwLFixo1ekVRVFCiYi84rVPQy6KoigRQQVdURQlIqigK4qiRAQVdEVRlIiggq4oihIRKgq6iNwsIttFZLnHfhGR60SkT0SWisjbgy+moiiKUgk/HvotwFll9p8NvDbz71LgZ/UXS1EURamWioJujHkK2FUmyfnAbcbmeWCaiBweVAH9sOePfyS9dy8AyYk0q+dtBWDZwB6WDgw1syhti2VZLFq0iHQ6DcDeHdtZv0jHAQTO8rthbHfVh+0Y28FjGx7zTjC4GvqfrqNg4SNtGX43fyNpy3uKb2MZRhZsxaSt3Lbt2x8kkchL1tO7h1k3OtHQsrYLQcTQjwQ2Or4PZLaVICKXisgCEVkwODgYwKlhYu1aNn/ln9n8ta8D8NRvX+bRX77Elr4hzrv+aT56/TOBnCfsLF++nHvvvZe5c+cCcOs/f4m7r/l2awsVNXathz9cAn/4XNWHfv7hz/OPj/8j46lx9wQ3nAq3nFtnAcPFr+a9wlfvWsptz/V7phldvJ3df1jD8BMDACQSO1m2/HKWLr00l+Zji9fy7nkrG1za9iAIQReXba5VqjHmRmPMTGPMzBkzXEeuVo01OgpAaqvtlY8M2TVxciIdSP5RYWxsDIDRjL0SY6OtLE40yYrx3k1VH7ppn32MZawKKTuHXSMJAHaPJj3TWKMp+++IncYy9t/x8c0NLl17EoSgDwBHO74fBTTPmtkVl8StXlEURekcghD02cCnM71dTgP2GGO2BJCvP1TQFUVRAB+Tc4nIb4AzgINFZAD4N6AbwBgzC5gDnAP0AaPAJY0qrCtZQY8VCvr6lPdrmqIoShSpKOjGmE9U2G+AywMrUZVkF7mWolD+5UPbW1GctkcXBW8CauNgqcGexr0ZL/KEf6Ro9rplQi5ZWU935vVUWoqG/YKk2EnzSFT9MbXwizPhf9/XmLwDpGXzoQeHxtAVRWkwG+e1ugS+iICHroKuKIoCKuiKoiiRIUKC3tpiKIqitJrQC7qx3Hu5qMOuKEqnEXpB15CLoiiKTfgFXXu5KIqiAFEQdPXQFUVRABV0RVGUyBB6QTdevVx0pKjSMmq/+Tp1yHo5/FikdEqLzrRj6AU9H0LPKLo66q6IvsE0njps3LAh6yHGjzlLk3S2HSMg6FlFD/9PURRFqYcIqKDG0BVFUSAKgq6NooqiKECkBL21xVAURWk1oRd04+Ghq8OuKEqnEXpBx2MulzCTSqUYGRlpdTEURQkZ4Rf0CPL73/+ea6+9ttXFUBQlZERA0KPXKLp69eqmnm/dwvmkkrqotqKEnQgIulIPm19exf99/9956o6bW10URVHqJIKCnvHUO3Pkb0WKh0iP7xsGYGjbllYUJ5rUsEp9/lC9cYupzSSdacfoCHqEQi5KWKlj6L/evyX4skiJ3TrbjuEXdPVoFEVRgCgIehb1cBRF6XCiI+hKfeibjqKEnvALuocQqcPuE7WTokSG8Au6oiiKAqigK4qiRIboCLrGWBRF6XCiI+iKoigdji9BF5GzRGS1iPSJyFUu+w8UkftEZImIrBCRS4Ivqjs6sk5RFMWmoqCLSBy4ATgbOAn4hIicVJTscuAlY8zJwBnAj0SkJ+CyViho5o9GXpSWU8fQ/w4dsl4OXzYpStKpjp4fD/1UoM8Ys84YkwDuBM4vSmOAqWKPX94f2AWkAi2pUhc6tLwJ1GHjKM3nHxS+zFky8r+z7ehH0I8ENjq+D2S2ObkeOBHYDCwDrjDGWMUZicilIrJARBYMDg7WWGSlEXSmP6Mo0cKPoLtVecXP/0eAxcARwFuB60XkgJKDjLnRGDPTGDNzxowZVRfWlQ59tQoK9QwVJTr4EfQB4GjH96OwPXEnlwB3G5s+YD3whmCKWIHc+hYqTIqidDZ+BH0+8FoROT7T0HkhMLsozQbggwAicijwemBdkAX1jRT8URRF6Ri6KiUwxqRE5EvAQ0AcuNkYs0JELsvsnwV8F7hFRJZha+mVxpgdDSx3mQK35KyKoigtp6KgAxhj5gBzirbNcnzeDJwZbNGqRX1yRVE6Gx0pqiiKEhFU0BVFUSJC+AVduy0qiqIAURD0LFLUvUV13pVOHRLdVOqwsQ79L6U2c3amHaMj6Ep9qNAHgA79D5JaxpZ0uhUjIOgqRHWhA7IUJTJEQNAzqDApitLhREfQG8B4Ms1Hr3+aBf27Wl0URVGUikRX0APw2Pu272PpwB6+de+KAAqkRB9T9LeaI+1jtNE6T9YWvixSTdoIE35Bb8ID0Ok3iaIo4SD8gp5FY+hKy5Giv9UcaR+js4bmydrCl0WqSdsgtm7dSl9fXwtLECVBVxRFaSGzZs3ijjvuaGkZwi/oDQy5tNpZ0niqoijVEH5BVwJBKw9FCT+RE3SNQFaH2qsR1DH0XyvWEqrp5dLphF7Qcw9AA5UpCg+ZNrY1gXpsrJenNkrs1tmGDL2gR5koVCSKojSP8Au6ap6iKAoQCUG3Fb04pBDEi5fOgFcZk0y2ugiKomQIv6Cri+6L3DDqojBOPdYbeeEFVr35LYzOn19HLhEia9taQmV6G3tS1pwl+2qffiEKREDQlVYx+vw8AEYyfxVFaS3hF3RtOPRFbhh1kL1d4pnbx1jB5Rlmcqtm1WBjje55Utacnr1cOtOgERL0zryArURi9u1j0iroitIOhF/QG4h23a5ALG7/tVTQFaUdCL2gl/TVVhWuirqsFbOPNlY6kLKUYyiZYuHekYafR1GqYkcfbFrY6lLkCL2g5xqzVch9EWQvl2zIBavx7RgfX7yWc15c0/DzBEId7To6mKyU2kzSJDtefwr8/P3NOZcPwi/oTaBVz1j7P9zNq0SX7htr2rlagY55KMWfj1acqLPtGH5Bb3vRUxRFaQ7REXQNuSiK0uGEX9A9CGTov9YRiqKECF+CLiJnichqEekTkas80pwhIotFZIWIPBlsMcvhEXLRSIw/NGTVAKq3qcEU/FUcMymUtYkp+JP90P7tT42hq1ICEYkDNwAfBgaA+SIy2xjzkiPNNOCnwFnGmA0ickijClxCEy6cPmSKooQBPx76qUCfMWadMSYB3AmcX5TmIuBuY8wGAGPM9mCL6Y3xiqEHEC7ppJ4HnerRNIbq75tOutf8kptJoaxtpOBP/tjOtKcfQT8S2Oj4PpDZ5uR1wHQReUJEXhSRT7tlJCKXisgCEVkwODhYW4l9ovLkkyBufK0MFKUt8CPobk988RPcBZwCnAt8BPimiLyu5CBjbjTGzDTGzJwxY0bVhXVFxURRFAXwJ+gDwNGO70cBm13SPGiMGTHG7ACeAk4OpogV8JibqzNfuKJPR4SG9myCbx8Iax5tdUnam82LYMuSVpeirfAj6POB14rI8SLSA1wIzC5Kcy/wXhHpEpH9gHcCK4MtapVE4LlvinjVc44OjVNWpo6h/xjYtMD+svCWYIoTcjw7Jdx4Brx4SzZR4TGdUPG7ULGXizEmJSJfAh4C4sDNxpgVInJZZv8sY8xKEXkQWApYwE3GmOWNLLijgFE4RcPp1EaiplKHjfX6lOKvoTgCD2eAVBR0AGPMHGBO0bZZRd+vBa4Nrmh+0QuqRJQoeBJKU4nsSFElmnSGxKm3rtRG+AW9yIvJvbkG0Q9dnytFUUJE6AU92/iRjUHqW6o7WTuVzoeuBguM3Fj1Gob+e1yfTsaUDOt3o9jrMkV/O4vQC7oqeECExI7hKKWitIbwC3oTMMDmoTHOvW4ug8MTrS5OTWTfYIp7U+iQ8wDJjVWvYei/xvdKEI9h/YV4VfGdac/wC3qVLtv8rfN5bvNzvtI6b4lbnu1nxea93LVwoLoTdgIh8e4VJer46rbY1uTExF+N/NmHPgvAsouXVXWabO7N1C6NpyqKUg3h99CLaNiba0Tf4EzIGpE6oo7T8ItSI+EX9CY/4WHvFaJefxOow8Zhv78aQk0m6Uw7hl/Qm3DhjDEd0HgY9d/XDOoY+q/2L8Hfi0pnCrcXERD05qIOroMWhAbU/IriTYQaRRtLTLKnC7ekjC9fwfjrSqaqVxQlAoTeQ/cS2CB8R6cDGpV2qvFVq+i/8BMue8JdUUWSkDsPUeS/H3mZtNW+1yX0gu5Jg2we+mdMAMtqdSkiSu09hgobQyPiPdRJbiaFsqmkIFE+bWMe1P95bA2PvLS1IXkHQfgFvUkCq41W7YH2AlFaTTLdvvdgBAQ9Y9zimEiA+ms8PocSQ3TiR21H7VN9FjoM4Rob0CjEz8j/rI1KEjXuHm/nqxIdQW9w1iKl2xpN2BtgFUVpLuEX9CaRG/rf1vVz9OkM6wc4qb/SUURA0JuxkDI5F12dZjfUKIrSDoRf0L1i6AFojFu/g9BLl9d6AEqA1DH030SqxSYQfFmhJFFn2i78gt4kcvVFSF10nW+7CdRh44JGUb1WQPABp05okwq9oDfyInXA9c8Rlt8alnIq0aWdK4bQC7rXm1XQTo72Q1cUpd0Jv6AXoaGFKqnHXGpqpQNpZ40Jv6AXr2Jf5+vQxLr1jL/0kp2Xi/vfvi9b5fG0S8h+UFsX199YdfdDMwdpt9g8ueFVPp7pXJpcWpdnN6BQSTuHXHS2xSLWnXMOACeuWlmwvRWVcjvfOEoT0OuvVEn4PXQPjybIZ6GgI1mZfNN795IeGgLgG/cs47ir/hhcIerE6zWx1LOpHq14Mvgbq+5+aMFB7ftK30xyw6t8eFOlaTrThuH30BtIwdB/H+lfPvWdgO3d3/H8hsYUSlEUxYPwe+hFA4sk97dBp4tCjNNhnJxnU08f6ibGoyJgfR/o5FyVeHBwDz889uJWF6PtCL2gN+t1vxWTcymK4s5nlq/nh8d9ttXFaDtCL+iNpBPEW+PfDaAOk9rXQyfnclJVL5f8lsYUps3xJegicpaIrBaRPhG5qky6d4hIWkQ+FlwRK9AEQeoI0QtJo2h7h7zCEbYKC35MIlXcD53wHFcUdBGJAzcAZwMnAZ8QkZM80n0feCjoQpYle40a/DxE9YGL6u+KBtEXICVY/HjopwJ9xph1xpgEcCdwvku6vwfuArYHWD7/FAl7EDIVpYFFYaejqh2tZJUa8SPoRwIbHd8HMttyiMiRwF8As8plJCKXisgCEVkwODhYbVndafJrVAe8tSmKElL8CLqbu1Asaz8GrjTGpMtlZIy50Rgz0xgzc8aMGX7LWJ5ihQ2wx5fbEnTV59FesWlTdDlDF1ds6+LWfvNlr0N7txE0Fz9j3orv56ztO3UWVj+CPgAc7fh+FLC5KM1M4E4R6Qc+BvxURC4IpIQtwhodZf1f/mXJ9mofuFZc/LsXDrBx12jDz6Pxd0VpL/yMFJ0PvFZEjgc2ARcCFzkTGGOOz34WkVuA+40x9wRYzjJ4VON1ak1yy5biM9SEZQyxJkaAjTF8+XdLmDG1l/n/+qGS/dX0ClBqpfrrrZVjKX7GvHndz51qz4qCboxJiciXsHuvxIGbjTErROSyzP6ycfNG07BXq1iMIJrimi2fVuaEO/ZNNPnMzaGjqqN2frcPIaELL9aAr7lcjDFzgDlF21yF3BjzmfqLVQXFgTYXDTbGVF1jSzxe+D2bcZvfE1bGDk31T9rcJuGjM71LpX50pKgHJYJec6NoAIWp4XzVVmDt3hinEqe0C+38rIRf0POz4Ltvr5VYzDWLarNt9sWv5KGX9goIAFXbItr3gQ8jtThFnRBecSMCgu5nnof68jWmds1qnYdeuD0qjUSd+Zh2Jv7W8W3+HdHO6wtHSNADvrAeStzuNX/eQy/XNaB9b0hFaXc05NJIjGX/KQ41ODSrVgfdFMwbXlvxmk3utzazvO17f4ccNaxSHaEX9MZ5zEEtKFvPsdUfXH0vl9oXNm4FISmm0oa0+9t1EIRe0HMdr4t1yXHtarqQzhi6I7N2vycyLywlbxSmTLdOJSCCWp81LK+DDSb73JW3ZnF34jZ/QBtMBATdali+zh4htTaENDvelj1f1eWt5ec1cRkn1ThFqUzoBd1kXdKAh/57NooWfb938SbmLNvimrZMNg0j+8Li2cslyPJ4danpdNQegZB1Sspbs/lvnu38lu5rpGhb40PHa2sULTzKyxm94s7FAPRfc66f4jWclowUbSKdEAdVlFoJvYeeC7kE/aCHVDhygl6tlxjOn6soioPwC7rxiKEXNIrWkm9QvVyaPbLI/uMp541w3aP6OlAr9TSK1n3jRg9fVlBTAREQdBNAzwKPjAv6odecTQBFqYZsDD2q/dA747nVGrIRdEK4LvSCnlcw74tVU08Tz0bR9r4poh5DjyrtPJy8VWjbcvVEQNDdQy51d3KxDLt7p9qfTT4mXW0l3+yBRTkHvZlPQxNOpc+20i60s6MfekE3RUP/3edDrylnvnPaJblvNQtKs7stWtlG0cafqxNeYRUlTIRe0BtWXQbVKNrsgUUhHhC6dc84IxOpsmm0ClFaTTuHgsIv6EVD/wN74h2hnDCNxq6222I99VbQYZ3Trn6Mv/rZs4Hm2Vxqvwnzw9xNwdZOppb+DiZwIXA5RxtflggIunsMvV6bBxVOaFGvxaZ46I0IuazaOhx4norSKYRe0D2H/tedsdf5qjtPy0aKll0qvXRfWOLh4Shl9dVpQS+XsLwONpisGWozR+Pu8Xa+B0Mv6CXWlYI/dpKaBhYVev61r1jU7Bh68xpFo7IKUtvRqLEVSuQJv6A3eeh/uz9i1ZqhHk1uZmWl/bSVdqGd78TwC7rX0H9nkjoHFhljavZGWzVSNOazuEFosnrqxQQ0H7raFai923GjaGenLvSCbiz319O6vceCBS5cN1ebTVPwtaZoiNEohKJ4E3pBb9Qi0bmKAtiyZzw/fW4T6+e6lqDzmg+99CTZD1Wfq61dlZDhen209vKB2shJ+AW9pNtiZlJ85yLRLXxla9XAoloSJbdtZ2LduoBPplRPNN+ulMYTekEvGfofXMYB5RNMNr5Pl4uh++y2mPssbPryl1l3jvtCHe2CViFKrYSla249hF7QsSpfpJouo1V7t0XjEX9vBlYdN+3Yiy9WTGMsi31zn7Z/Ywc8IIoSJsIv6Lk+u7kNAWXr0W2xjpBGMzDbV1Z5QHVl3XXrbWz8/OcZfvRRmlldhSIIEcB1b/fpmdueJjx77ezph1/QvYb+OzbXdAGKPf/s9LlVlinoaz97yWZO+8/HSHu8mVj3fgmAWNVX1l9Bkxs3AJDavl09dKUjSQ0P8fK8Z1pdDFd8PfYicpaIrBaRPhG5ymX/34jI0sy/Z0Xk5OCL6k7Dhv5b6YKvVXmIBSGXYMv19buXsXXvOCMJ91kJTW6l9Ab7tC3S8s7yYDvpt4aH7b/5Eff919VYRRrRDnRVSiAiceAG4MPAADBfRGYbY15yJFsPvM8Ys1tEzgZuBN7ZiAKXUOKplvZyqQXj4QH7qTcKYuiBt9Vm+5m7Y2XqaN+/v2pD5dMH9eo58vw8uo84PJC8IkEo4kudS2rvTvtDG9a3fjz0U4E+Y8w6Y0wCuBM435nAGPOsMWZ35uvzwFHBFrMMPua9qK3XYuURqN7HmoYN8svNpuhxgmbOtpg3bH1n2/CZz7D2zI/UXRxFaQ7tW+P6EfQjgY2O7wOZbV58DnjAbYeIXCoiC0RkweDgoP9SlqNIeFMY7j11CtvrfB0y6eqOL/BWnTH0espQVEnt3DdRsReLlXtD8RL8ou2BeNlt6Kq0krrWHSRvTm2jAHyG2UpsVXpM0I2Z7dg46kfQ3ZTB9ZeIyPuxBf1Kt/3GmBuNMTONMTNnzJjhv5RlKB76v3w/w9Lje0kWnLeGjItCLnl99JxX1/VzUBd9cHiCU/7jUcaTVqZ4Ho2iJhNyCeSsFQjwhm6/R6M27k2/i77UIa0uhtJI2tdBrxxDx/bIj3Z8PwrYXJxIRN4C3AScbYzZGUzxfNCw2RaL+6FXuIpOEbdsPzjIEu0cmfA6nTvlihtUPChXiPrzK3lzKEKCNmiDuCL597Ab+qs8rnA+9OzfNlaOJuBv0rdW3hTtd0P68dDnA68VkeNFpAe4EJjtTCAixwB3A58yxrwcfDHLUKRsuVkGC2bUqiFbR8ilpytvJk8hLeg+GXyjaLzo5vby/HONomXyqksmsuVYeJuzNPXkaOfQ4eLlShu+0it52vHyVBR0Y0wK+BLwELAS+J0xZoWIXCYil2WSfQt4FfBTEVksIgsaVuKS8mWG/gddW1qGD26wf8Y5bzqssrPkEUMPilisWNDd01WKoddNNt+tywjSQ/Gbk9vvnujrY9THKFdFCYbsTH3tp+h+Qi4YY+YAc4q2zXJ8/lvgb4Mtmk+8hv7X2xfcWHRbdl9vpzh6XUNTFEMXETAmsGtePDeL54tCrh96IYn+/rL517aqU3AhF6uOCmjdn58HwImrqhwl27Z03tuKMQbLGiMe36/VRfFNO46JiM5I0ZIpAOrDVDuXS7Ggl0m69pxzGbzuJ1WV5xv3LCv47tUoajz64e+Y9b9Vnc8PwbbyR0vEdu6bqJzIhXYUiWawYcONPPHkm5mYqLf3WxPsJ+3roYdf0D1d5jrztaycOPoSroLh/uXfDhLr1rHjpz+tqjjP9BW2M3v/bLvM+8bdR5L6oRXdsXyHXBpaiuBYOzjS6iKEim3b/wjAxMSWhp2jHbsZBk3oBd0UeeaBrRNgWZjcohaOvKrutljDuX1QqVF0857x2jP32wYQZLdFCf2tWIC28VZLCA3WhvWDrxh6W+MVGqnT2MYyBV3pKmVXPLBIXCqDIPHKN5DzWRbE42WT7O7bj/S6O4I4G1C53GF43J33gN81XZXw0o7hsfC7RZ5D/43Lpyqw0pALuZSezrMcZRNVR7lXRM+BRVVe0txN6XcwVKamSuztJj00VNW5ylFPo2g5dt12GyvfcCImkWhI/k4K2+eD+D3tJxiNI4Q1YBuGcEIv6KZ4zhVT9LfWfB0hF7fsAVLO6QucMXTLpzh6MGq6WZg8suyxlWLonvh5bhrQ7bIy/h7oaq2ZbQxO791b5ZHV4xT0Wusng+noeI2b11uLbjYyXp7t9daGeh5+QSddeaRovfOhG4/sN/3zvzhP4jxjbuRfpTOPJdJsGhor2DY3eQJL00ewdPOw53HvvuZP7HDpSWHV6uk4RaQFgu5WeQaBdHfb+SeTFVLWj/OtqXMluTYaPt1zQ8hfb8vHymnNIPSCbtKZ3hzF08rWW6sbq6K3aw3nBbdkci6f9+fFv3yB06/5U8G2VGY+lkoV0Qvrd5VsW2qdkPucTOeFWaowiNfUwWWOqDK9Ww4NeqCzK300oZKqx2MrEDQfM4hGlmorRWmdjZzP5x+XNa53TjWEXtBJFz2o9eiCM2ziGPpvjHF/FXRu8+iH7leUjTEYY/jVvFfYayZl9uZ/zAkzppQW1yXvWemP5j7/xU+fLntuT+qZOrjaU2V+g1PQy3k7psArsrB8CnUzuqwVhlzC6HHWx46xHZz3f+excXhj5cTF5OzVuOvUyHtguI5uwkESekE3uWlyiy5WLQs1F3jZxnV+Ec97wlkBWCY3srNYm7xuquO/Nodv3LOcf/2/5UxkOh85T3/o1Eklxzy3dieJlMXuEfcGv3W93/YorAt1TF1Q14OSOZezUdTvQtff+c53uPnmm/2dp8rpkGvBctxpdfVyydoiZJXCnHVz6N/bz69X/rqGo8PxWycffRNJk3ne2vAFKvSCXuKhZ6jp9igJuWQ+OpMUeOXO5IWTc2Uf6BJxKiOWv5q3wbtoLnfPr+Zt4PwbnuFt332Evu2l8fZ4r91ou23vOLcf/QHSPgPVxaNkC3DJIj00hDVR28jIvD3KdxH1KvnAwED+OLeKINt9tBmC7vTQgxCokIVcco2F9a0CEExhGkTX/n256+L8nW5179XzrubNt765WUUDIiDoWQ89tzSbiwr7fi6cXn3aYk/P/v7zcAqGZeVu7hJtzKRLxOJMpMqLjPMe8Tr/yi127427F24ivW9ffkcsP7DoW/cu59lXvZEBa1omY/9TAZeUyeXYvbPvY8OnLy6fp+epMg+Hs022ViErJ9pVCvquzSO+GrqsRIK9Dz1sh8ys8g+4HxoWFjAGnp8FY7srp62R+iqxcHjo4LhXK8T7f72qljeV+gi9oOMlivU2iloWCw99fWleXt0FncrtiKEXi1P2HJ8861u8/hsPli2P8yZZv6P8UHIR2Hjp3xVsG9v4Ke5bstlx3/k0Sg0NiGNLllR9jPNcBYO4yhSz3L700BA7Zs0quBa53kZV/KbdW0f4zXfmMW/2uoppd1x/A5uuuIKRp5/2nCeuehogbhvnwYNXwux/cN29de0arIDeYuqplNpxsI4XlX7n9NQBTSpJntALeu5BzdrWpZuL7xusYJEK95vbM6eCGHq+l0vJqTPlHe4pbeQs5qJbFrMrEx/fPlw+pCEIYwsXOgoqpPa9kb//zaKKDTYvTDuFtdY0ErEulr3qhKrErx4mRkcxKbtsxmcMPTE26rlv6/e+x+CP/4d9jz+e35gNA6T8N1qN7LFtvnXtnopps2MRUtu2FXZbrEuTAxpM4SSVuX9cPPRt69fyq6//E8/+vj6Psp6QS3j8c3eKr/fYql38es01zNx3UlPLEXpBL36Vduu2+NIGnzO4OYXEEZt37+NSmN44Y/kmX460I81EKs2SjdWNrnx81XbWDu6rmK5EQExv7uNz6+yJvVakDpWDA+4AABd9SURBVCPpcsnnTT+Vm9Jv5WdvuYCvvveLrNs5VpImaEb37uH6Sz7O87P/ABT2n3fT8+ymB274L888rT12+Ml1VGgVlVRV4hJzVkTOPNpMosrUMCNDdk+r7ev7mlUab0LWbpCl+HonNtptWq8fO76p5Qi9oBvLYuekA/jFlJM8PfEHX/Ip6AXdFvMena8JHZ0evXHE0B0H/9u9K/iLmxeydb+D/JUH+Mrvl/DBHz1ZMd1P/tTH7t79y6bZbqby5P7eHsP6Aw4HYN3O0Yrx/SwGSGZEbe6aQV58pbRvvBuje+yK7eUXnrM3+Iyhb3+l37ss5ZYj9AgnjEyk+P6Dqwp/b83xb8fnurxrKfobIC62MbmwV1CnqCGnJvToCbx9wkd+za7WQy/opFJce8pF3Db1JJYM7PFoFPV3IQtCDek0+yUdnmq28c6Rl9OrtJyCYEzu/nz81ptym5cO2K/w+7on+ypPtWyZ8qqKaUZjvYXfE6We6xfuX8flv1rk65wrjjyYR958ApbAp37xAn/1s+d8HZcfPu3SD73s5SoXRM9fg/S+faR27swJxfqhCY676o/M7y+scK5/vI+fPbGW387P953OT3ddnQA4K6JataNxMWT3ft79Sxdxzw++m9nl79w79tm2fHrNjqIzBNHLpUZKTtn4MhTcH0XKnet52mRJD72gG8tiIm732057vFb7bqxyxsFTaY7du83+bBwheocncf2hpznKURRDz7B5zerc55cyPVKeOvJknwWqDj/D/l+adBSLDsqPJv3kQ/k4ccxxgz66cptHDoXn2DR9qn3uqj2swkaGgj7/RddraDQBy3dD2io/v0063+Np679/hzWnvye379ktdq+fexdvKjhmImlfq0TKee9U8VsKhy4ETIAZeizK0L84v3Sf3wps6YD9dvXLZ9YXnaLNwkxNxPOXN7luC72gk07nhMgyzhi6j64pRRSMDk2nCge7ZJ5W54W7d/ob8/tT7jF0t8FJ8w99g6/yVI2PB2oi1sNVp1xM/+Rj+MnxX2A44XjjKDp+5003sfINJ+a+bx8e5+ujR3P2BT9k07TC8E7V921uemE3D70wt/95bA1sHCE+MFr+RNnrZ2DvffdlzlNUcRQd7+pN1jJoUaRA0Kv20J2md1yHifQEn3/481VmVu4ERQULUISD6LZYqW93O5BbJ8HHrKSCNHVhjdALurEsxONhzeIWk907nmRO0fwLxhk2SaVzYuzZKOo8h0cM3W2OkkYt5lDNxFz3HXZuybbVBx1b8H37D38E5N84Tv3eYzyWtPuyLzn2UMB+DA0w94i3epdrZKRkYI9kbZCtjB1lT6fTbP2P75F45RX7u3OitDI/0bV3Tk7Qq48TV/scVlqpqhaWbF/C81uerz8jDw+9cL1cn45PhWTNFLCWNqEW9GpyvzEFaWoIKvSCTipV0Odb8q5fjrTLu/BXfreEL/5qIeucPUicYZN02j2u6yEo6WxlEO8hPZxiZCLTHQ9h2cAe7l+6OV/kWPnFI2rlnle/tyH5es1UePYFP2Tuq06jb78TuHbm3+S2f3v2ivyx6TSrT5nJ1u9+t+DYuev3MPegd+eeicePfntu3/jatey+4w42/K2LZ1o25JIqTZOpSCTb8OdxuPOBLD9m1RtndfLs2p1cPafGRasdk3NVE8YYGk3wgwdXkfIYPe2GiDAWm0RCuuvuYeI3hn7Fn64oGUGZtOKkrfDKUclVKmjkb97cSOG1IHmPLDuTYIEn7viYchH0gd12g+doolDE85/zIRdjYMWOFZlzuT9gVvYhetc/sOuuXUyk8gNmzrv+ab7063wj46b9Z/j6fdXy3BH1DTM+Zduqgu8PHnsqAMMPP+J5zILppzAeL5xn5pZn+3Ofs10Ih/5wFwDjyTSDwxNccd96Fh94MsYY+g48gjtO/Ej+mMx1TW7ciDVWRRfKtMXs40/n5Gck5/HnujBWeKgSa9ey6/bMCkw+RPTlbcM8uHwLGEMaIW3g6VfyfeSveWAV//tU4cCkZQN7Ch0IBxOjB2Ol9mf+un0FYbDi++2aB1axaqv73O7fuf8lfvrEWh55ya39wzvkctOxl3D7UReV7qsSv5XPnzb+qWTbJ+76JP/23FVVVyrlUn/1D0tYvdV7Cup6KVtxORpFm/nGEsol6JZv2sOBk7u5f9FG3jj5QOIZzzptuZu4sMHLxvXWSxeGXKxMWKB/aJBXdswBzkUEnnx5kEduuQc4In9oKsVQz/584uDDOJH8qM5isWtn4kWi9z9v+zhvGVzLxn//AWbuIojlveifHP+F3Ge3qXm3fu8/OfiLX2Dz3gn29OzHgSZJcutWPnnbYhbsytv5e1P/Ct5feKyVyHcZtcbG8hW1uIewErE4q6YfyzusND9/83kApCXGwJRX8Xenf5U37VjHR7cPAtMoloB1mcWcd//ud2xbO5eDPvXJfHQilebOFzZw+msO5uiD9is47sz/fgqAZwX+/IJrYQFAqZA+27eD1x02lYP37+W86+3ZL/uvyYe7xpNpJnXHGVj5aQC+umYDc46OcwuASIlIznpyLbOeXMvib32Yt37nEW655B2c8fpDcnmBR+Oso1eRkA+LZHMf7Sr8fQ8u38Kpx7+Kg6b0lGQ1nmlIfmbtjpJ94D/clLYMQ6MJervtN9YtI4fhJdGDwxO843uPcutnT+V9r/N2iIwj/Pq7BQPM798Np0wr2FcN8/t38cYjDmA/t53OTi7lQoFNDLmEUtD//Cf5aWFf885LmDZhez0pj1Yp3wNFC0Z75kMuL2+26D3E/jywe5SLb34Bp5gDpNMWOyYfCMBKx8v3Q4d82N/J24CRrtLK53Nnfq3icY8ffEbJttOGT4bvPwtA75nf4Ianf8KdX7mOBUefXjG/lGOiL5NMcu/iTLjKY/bLvz/jn9hwwGH8YtVvcu0pDx73Tn568l8CsPzgE3jd80/Ca95Xci88+XLpGIVUZmm90f5+vnX3Dg47YBLPf/2DrmWdqDDh2UU3zePVM6bw2FfOKNm3oH8XH5v1HJe//9UF2/uG8v3pvd4Isz2mZj25Nifo2SYEEVi1dS898RgnzLAbr7eNbONQYHB0G4cA7/n+4wyPJ7nm1fmX9Kxtdu6b4LI7FnLKsdO56wvvZs9oktlLNvHJ045FRLjqrqWALewX/fx5LGO489J3OfKxM1q+aQ8LN+zmlGOnc+1Dq7n0vSfQFc+f7+o5K7np6cKeMl6CvmyTfU1umruOi29+gfhJ00gfPaXymgVFF/yHD61mSm8Xn3n3cczv38Wnb36Baz/2Fv565tElx24fHuevZz3HWW88jFkueZuCGHrxXsn938yQSygF3clYVy8DmRBGKp2/vDKRN+KfvXpayXFubURb9oxx2xs+wqdWPZTx0Eujqc+vcx84E9Q8GK1kxcEnVE5UAxNdPfztGV/xnd45c6MZH89NXRDbXTr9wfL0YWw44DAAhmNduR5PWTHPcvdr3mfnl7mQz/bt4I1HHFiS31gizVOv7MLCkJ6wwzU7902wcu7jjB7zVuat38kXz3hNLv0sji3Jo5i1g+7z8DyV6cd9w+NrC7Zn77oXRg9n5x73+2rDztHc7xlf/TKkUzlPMCZw1o/nAvD59x7Pz+eu57ZzdnAosHt0jEMgt0rWF1fkxy6kdu7EpNMk03Y+G3eN8vCKrfzhxQEefmkbbzryQN52zHSGJ/JvUM+utUch75tIISIYAyNjtlfvdLwAnlhtV56Tj3k1sZ5BFzG3SaQsFm4onKIge92ybyFdq/eQPtqePuOHjLH4pVd422/H+N55B7seR8riPx5Yw28X2h0hvv9gPrz46xc25AT9mgdWcf/SzTx95QcYnbDPla08izHG4sH0OzgztqBg+2/nb+DKh5bxv+zX9EbR0Au6Mx6dtiwW7Ryme9so8cH8w//y9hGeXbuDXz7Tn9uWE3SHsb/8+BYWvuHDnL5lGW9LpXJCYScs7wmk0xajXb1l0yj++Py8EX7QPZmpyTGs8fx1jG/Jx9PXDe4jaWK8mMp7Vntik5joKg0ROPntgo385fIHuGj8TfQ4vMUb33w+5617hgtueIbV24bpPhDekBl5m06nmHP9j3Jhph88mB9bsNN0++q2/pTjTWDnvglueno9P3tirWf621Mf4psbLoCbtzP1xNL9V929DIBFG4d45qJ/Yfr4MNaVvwDItd8A/HyuLZr//cAwf9YLY6NT2Tzk3i4x3tfHrttvh7+4ELDnD7r09nw/9U1DY54x6Tf920N86v1xUnvezu9XncwHD/VewcckpzOywb0rZtpYXP3ASn75TD+XvtceNn/Ls/3ckxk/kK3cJW2Ib7QryntIwgT0L9rE38ycwuMb38PKnbbRsqt2TXpsC7/1KM+iDfnpOGY9mb8mqcwrT/Hc9lnNmL1iJ99M/hPf7roFp2tw5V32tbmeCT5gNIZeFrceK1l+/OgaVm0dprgPye0vbuP2F+34Zu8h76F7+jxWbRnO5WcyvQmyoyavOv0y3mPynvjh0w07Kzy1+xJprnzvF2v4RUox/aPw8XO/y38/eR1fvqe/cKfA/y0a4J9+uwQ4pWDXhnF/jXL/b/xNACSKeoMsmfEaVm+z74ukwLLJduVgSZy9Xe7TKjwqh/g656dvfiH3+dzrnmbr3nHPtAJ8M/XZ3PejBr3v+UTK4nMfzoTFMo2hV89Z5Zke7PVo3bj/yA/xZxs286GrH3Pd72zYd+P2x3vpnnYcAJfdsdAzXWL3Oz33nXn9EIdPsz3jG+fmPfihUbun1SpHhdL90hAD3YXXJWUZ7lj58dz3LXvGiW2r3LA+nkzz5d8tzn3fumecD/2X3U7Sv3OU2d3v4qPx5xjfej7PTZvMGTueY+eIXaY15igWPrWOQ9PTOTyW9+Ytst16myfo0szaw8nMmTPNggULKicsYuuecU7zuOHq4Ud/fTKzHlrOmr3hD51EmTOHHuXhaR9qSN4f2jCfR495R0PyrocH7vlnTrzQbkc4bry2GRHfKn3c0/stFlsncEHiPzzTdWGRCnfnt5r4xcUz+dyt5fXowZ4rOSvxfQA+u+FWbj7mYgCmM8xu7BHT02WU3SbfhHp89xCzv/lRpvZMDaysIvKiMWam277QXbmxZGME9yu/X6JiHgIaJeZAW4o52P3966XCMIocnSjmAPct2VwxTVbMgZyYAzkxBwrEHGB9cpoOLCrHo659bBVF8YNbF1MF7llcWdBrZeErlefVD4rQCXq8rtV3FaUzMbludCrozeYzv1jqOhamEfgSdBE5S0RWi0ifiFzlsl9E5LrM/qUi8na3fIJgaNR9hXtFUbwxjn7RSvMZe+qJpixUXrGXi4jEgRuADwMDwHwRmW2MecmR7GzgtZl/7wR+lvkbOIl053oYIhMYU7lrpBirYROAKeGkc5+a9mDzFy8nG9R5zROP033YYWXT14qfbounAn3GmHUAInIncD7gFPTzgduM3WXmeRGZJiKHG2O8O6PWyNRl1/FwzxNBZxsK4vuDSdt96NPeS2sSmwxWAqjWIYhROMNUk8muvWGVXz617ZEuMP6XMK2Kh3v+pabjJmG/2b4p1l9zHkrtxD+bfzfacNsH2BU/knd8xXuOpFrxI+hHAhsd3wco9b7d0hwJFAi6iFwKXApwzDHHVFtWAA6c0sUmOZTkeIyuXouubsPEWIxUIoaVFrp7LJKJmC16MyZzQHIvibE4XT0WEjOkEjESY3EmT01hpSE5EccYmDQljcQM8S5DcsLOr3dKGhFDYixOKhGju9ciFjeM74sz+YAUsRikEkL3pMxkUhMxMBDrgniXvW1iNE4sZvtH3ZPsxaOtlCACE2Mx4l2G7l7LPhbo6skoagxIC+m0YKWhZ5JV+L48GRJjcbonpREBK23naVkQ7zawnz1KLjURI95tiMUzbe0WJMbjSMyQTsbomZQm3m2w0kKsy4CBdErsMmfyta8dxOK2/RDo6rZIjMWIxfPbUwlh8gEpjGWXRWKGdEqId9m/f3wkTjoZo3e/NMZALAaIXbZ00r6eAKmeGPFui1TCtk86JVjxOGPdkzkgNZwr08RoHMTQu59FOinEuw1je7vY/6AEVkoY2dNNV7dhvwOTpBIxjAVdPYbEeIzuSRaJ0RjJhH0vgH3NUpl7Z2xfF1OmJTFpIdZl2duGu+jqtjDGtpVIxh6Z6xbvMhgDEoPkeKyg/JOmpO37dCLG5Klp4t0WxhIsC9JJIZWM2fcoEOsytg1j9t+xfV30xlMcm97GpqmHOidjzNkfA4nxGLGYIZWMsd8BKfu3ZO75WNxwzOgg82OvZ6hnfwTo3T+NlRaS49mpjO3rbYwwaWqKsb1d9nNiCfEui+R4jMR4nO5ei94paTCQSsSYGLHvQ2PEfgZ77WdtYiROz2SLidE4liVMmWb3205l7/Ve+/em04JJQ1dvipGhXqy00DMpTWI8Tu9+aZITMSZNSZNK2vdVvNuQoJtErIcpqRHGh7tAsPMXEEmTSsRJJeJMmpJmeFc3sWkxepJJeianmRiNE+82GCtjO8jZqqvbZOxvP1/JCVtXJk9N2c9Vxs4YMEbs52A8TrzLQmL2s5O9J7p7LFujeux9TrpSB1Qrfb7wI+huYbfiNzg/aTDG3AjcCHY/dB/nLuGTl19Xy2GKEgneXzlJWdqzY6YSFH4CrQOAc+aao4DiPj5+0iiKoigNxI+gzwdeKyLHi0gPcCEwuyjNbODTmd4upwF7GhE/VxRFUbypGHIxxqRE5EvAQ0AcuNkYs0JELsvsnwXMAc4B+oBR4JLGFVlRFEVxw9fkXMaYOdii7dw2y/HZAJcHWzRFURSlGrSzsqIoSkRQQVcURYkIKuiKoigRQQVdURQlIrRsgQsRGQReqfHwgwH3JccVtY03aht31C7etKNtjjXGzHDb0TJBrwcRWeC1Ykeno7bxRm3jjtrFm7DZRkMuiqIoEUEFXVEUJSKEVdBvbHUB2hi1jTdqG3fULt6EyjahjKEriqIopYTVQ1cURVGKUEFXFEWJCKET9EoLVkcNEblZRLaLyHLHtoNE5BERWZP5O92x72sZ26wWkY84tp8iIssy+64TkdCvFywiR4vI4yKyUkRWiMgVme0dbR8RmSQiL4jIkoxd/j2zvaPtkkVE4iKySETuz3yPjl2MMaH5hz1971rgBKAHWAKc1OpyNfg3/xnwdmC5Y9sPgKsyn68Cvp/5fFLGJr3A8RlbxTP7XgDehb261APA2a3+bQHY5nDg7ZnPU4GXMzboaPtkfsP+mc/dwDzgtE63i8M+XwZ+Ddyf+R4Zu4TNQ88tWG2MSQDZBasjizHmKWBX0ebzgVszn28FLnBsv9MYM2GMWY89P/2pInI4cIAx5jlj3423OY4JLcaYLcaYhZnPw8BK7LVsO9o+xmZf5mt35p+hw+0CICJHAecCNzk2R8YuYRN0r8WoO41DTWZFqMzfQzLbvexzZOZz8fbIICLHAW/D9kY73j6ZsMJiYDvwiDFG7WLzY+CrgOXYFhm7hE3QfS1G3cF42SfSdhOR/YG7gH80xuwtl9RlWyTtY4xJG2Peir2+76ki8qYyyTvCLiLy58B2Y8yLfg9x2dbWdgmboOti1DbbMq99ZP5uz2z3ss9A5nPx9tAjIt3YYv4rY8zdmc1qnwzGmCHgCeAs1C6nAx8VkX7scO0HROQOImSXsAm6nwWrO4HZwMWZzxcD9zq2XygivSJyPPBa4IXMa+SwiJyWaY3/tOOY0JL5Lb8AVhpj/suxq6PtIyIzRGRa5vNk4EPAKjrcLsaYrxljjjLGHIetHX8yxnySKNml1a2y1f7DXoz6ZewW539tdXma8Ht/A2wBktieweeAVwGPAWsyfw9ypP/XjG1W42h5B2YCyzP7riczSjjM/4D3YL/qLgUWZ/6d0+n2Ad4CLMrYZTnwrcz2jrZLkY3OIN/LJTJ20aH/iqIoESFsIRdFURTFAxV0RVGUiKCCriiKEhFU0BVFUSKCCrqiKEpEUEFXFEWJCCroiqIoEeH/A3zHeCHyfG6AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'pard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-155770737a5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Augment data, this may take a bit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mnewaugd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_augdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_exp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_exp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# Enconde theoretical labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\Jupyter_lab\\Compare_with_others\\autoXRD.ipynb\u001b[0m in \u001b[0;36mexp_augdata\u001b[1;34m(data, num, label)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;34m\"#        \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;34m\"    return newaugd, pard, crop_augd\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m    ]\n\u001b[0m\u001b[0;32m     91\u001b[0m   },\n\u001b[0;32m     92\u001b[0m   {\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pard' is not defined"
     ]
    }
   ],
   "source": [
    "#Load experimental data as dataframe\n",
    "exp = pd.read_csv('Datasets/exp2.csv', index_col=0)\n",
    "exp_arr = exp.values\n",
    "#exp_arr = exp_arr.astype(np.float32)\n",
    "#print(exp_arr.shape)\n",
    "\n",
    "#Normalisation\n",
    "nexp = normdata(exp_arr)\n",
    "plt.plot(nexp)\n",
    "plt.show()\n",
    "#print(nexp.shape)\n",
    "\n",
    "# Input the num of experimetal data points \n",
    "exp_num = 12\n",
    "\n",
    "# Process data experimental\n",
    "# Define spectral range for data augmentation\n",
    "exp_min = 0\n",
    "exp_max = 1500 \n",
    "theor_min = 0\n",
    "\n",
    "#window size for experimental data extraction\n",
    "window = 15\n",
    "theor_max = theor_min+exp_max-exp_min\n",
    "\n",
    "# Preprocess experimental data\n",
    "post_exp = normdatasingle(exp_data_processing(nexp, exp_min, exp_max, window))\n",
    "#plt.xlim(0,1500)\n",
    "#plt.plot(post_exp)\n",
    "#plt.show()\n",
    "\n",
    "#plt.xlim(0,1500)\n",
    "#plt.plot(ntheor)\n",
    "#plt.show()\n",
    "\n",
    "#print(post_exp.shape)\n",
    "\n",
    "# Specify how many data points we augmented\n",
    "#th_num = 734\n",
    "\n",
    "\n",
    "#Import dimensionalities\n",
    "label_exp = pd.read_csv('Datasets/label_exp2.csv', header=None, index_col=0)\n",
    "label_exp = label_exp[1].tolist()\n",
    "\n",
    "# Augment data, this may take a bit\n",
    "newaugd, par = exp_augdata(post_exp, exp_num, label_exp)\n",
    "\n",
    "# Enconde theoretical labels\n",
    "label_e = np.zeros([len(par),])\n",
    "for i in range(len(par)):\n",
    "    label_e[i] = space_group_enc.index(par[i])\n",
    "\n",
    "\n",
    "#augd,pard,crop_augd = augdata(ntheor, th_num, label_theo, theor_min, theor_max)\n",
    "     \n",
    "\n",
    "\n",
    "#prepare arrays\n",
    "X_exp = np.transpose(post_exp)\n",
    "X_exp = X_exp.reshape(exp_num, exp_max-exp_min, 1)\n",
    "\n",
    "X_exp = X_exp.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_exp[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
